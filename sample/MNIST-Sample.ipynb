{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Sample\n",
    "\n",
    "This notebook creates a sample model for MNIST using Tensorflow and SenseTheFlow.\n",
    "\n",
    "As a sample, it is an overkill that will use Keras Resnet50 implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from SenseTheFlow.experiment import Experiment, Mode, ExperimentOutput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Model\n",
    "\n",
    "Models are now sub-classes from `tf.keras.Model`. This is to make user code and the library itself compatible with future Tensorflow 2.0 usage.\n",
    "\n",
    "Such models should:\n",
    "* Define layers in its `__init__(self, mode, params)` constructor. The easiest way to do so would be by using either `tf.keras.layers` or `keras.layers`.\n",
    "* Call layers in its `call(self, x, y, mode, params)` method.\n",
    "\n",
    "The `call` method must return a `ExperimentOutput` instance. Its property `loss` must be different from `None`, either a tensor or a constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST(tf.keras.Model):\n",
    "    def __init__(self, mode, params):\n",
    "        # Always call `super` constructor\n",
    "        super(MNIST, self).__init__()\n",
    "        \n",
    "        # Define layers\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=16, kernel_size=3, activation='relu', padding='same', data_format='channels_first')\n",
    "        self.conv2 = tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', padding='same', data_format='channels_first')\n",
    "        \n",
    "        # Example on how to add L2 to a layer, no need to manually touch the loss term, it will be automatically used\n",
    "        self.conv3 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same', data_format='channels_first', \n",
    "                                           kernel_regularizer=tf.keras.regularizers.l2(0.001)) \n",
    "        \n",
    "        self.pool = tf.keras.layers.GlobalAveragePooling2D(data_format='channels_first')\n",
    "        self.dense = tf.keras.layers.Dense(10)\n",
    "        \n",
    "        # Optimizer and other params\n",
    "        self.params = params\n",
    "        self.mode = mode\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=params['learning_rate'])\n",
    "        \n",
    "    def call(self, inputs, training, step):\n",
    "        if self.mode != Mode.TEST:\n",
    "            x, y = inputs\n",
    "        else:\n",
    "            x = inputs\n",
    "            \n",
    "        # Call layers\n",
    "        outputs = self.conv1(x)\n",
    "        outputs = self.conv2(outputs)\n",
    "        outputs = self.conv3(outputs)\n",
    "        outputs = self.pool(outputs)\n",
    "        logits = self.dense(outputs)\n",
    "        \n",
    "        # When `mode == Mode.TEST`, `y` will be None\n",
    "        loss = 0.0\n",
    "        if self.mode != Mode.TEST:\n",
    "            # Compute loss\n",
    "            loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "            loss = tf.reduce_mean(loss)\n",
    "            \n",
    "        # Summary examples\n",
    "        if tf.equal(tf.math.floormod(step, self.params['summary_steps']), 0):\n",
    "            with tf.device(\"cpu:0\"):\n",
    "                tf.summary.scalar('loss', loss, step=step)\n",
    "        \n",
    "        # `call` must return `ExperimentOutput`, and it must be constructed as a \"key=value\" object\n",
    "        return ExperimentOutput(\n",
    "            outputs={\n",
    "                'probabilities': tf.nn.softmax(logits),\n",
    "                'number': tf.argmax(logits)\n",
    "            },\n",
    "            loss=loss\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define some params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'model_name': 'mnist-test',\n",
    "    'learning_rate': 3e-4,\n",
    "    'batch_size': 128,\n",
    "    'summary_steps': 1000\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the data pipeline\n",
    "\n",
    "It can be done in multiple ways, the only restriction is for your `dataset_fn` to return a `tf.Dataset` instance. Here, we will use `Keras` to directly obtain images and labels, but one could read from disk or whatever other option.\n",
    "\n",
    "Here using a generator might not be the best idea (performance-wise), as we have all data already loaded into RAM. However, the general case will be generators, thus it is the pipeline used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_generator():\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "    for image, label in zip(x_train, y_train):\n",
    "        # Here we simply yield two values, but you could easily construct other returns.\n",
    "        # More examples are provided below\n",
    "        yield image[..., np.newaxis], label\n",
    "        \n",
    "# `dataset_fn` always receives the run `mode`.\n",
    "def dataset_fn(mode, params):\n",
    "    # Create a dataset from a geneator\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        generator=mnist_generator, \n",
    "        output_types=(tf.float32, tf.int32),\n",
    "        output_shapes=([28, 28, 1], None)\n",
    "    )\n",
    "\n",
    "    # Batch inputs, make sure all batches are equal-sized (drop_remainder=True)\n",
    "    dataset = dataset.batch(params['batch_size'], drop_remainder=True)\n",
    "    # Prefetch some batches\n",
    "    dataset = dataset.prefetch(8)\n",
    "    # Repeat for 100 epochs, leave blank to repeat indefinately\n",
    "    dataset = dataset.repeat(100)\n",
    "    # Return the dataset\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Physical GPUs, 2 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# The new way to tell TF not to use all GPUs but only the exact amount needed\n",
    "# The next cell will attempt to use GPU space if executed, so do it now\n",
    "#  otherwise it would be fine to do it just before running the model\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(5, shape=(), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Errors in the above functions are particularly hard to debug once in the network\n",
    "# you can manually inspect everything works like this\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    dataset = dataset_fn(Mode.TRAIN, params)\n",
    "    for x, y in dataset:\n",
    "        for batch in range(params['batch_size']):\n",
    "            print(y[batch])\n",
    "            plt.imshow(x[batch, ..., 0])\n",
    "            break\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 12 18:28:50 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.43       Driver Version: 418.43       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN Xp            Off  | 00000000:03:00.0 Off |                  N/A |\n",
      "| 30%   49C    P2    63W / 250W |    394MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN X (Pascal)    Off  | 00000000:04:00.0 Off |                  N/A |\n",
      "| 23%   44C    P2    55W / 250W |   8100MiB / 12194MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the experiment\n",
    "\n",
    "Experiments are executed in two steps:\n",
    "\n",
    "1. Experiment discovery: That is, given the experiment name (or model name) find the corresponding saved checkpoint (if any). This process might not be completed immediately due to:\n",
    "  * Remote execution, when the model has to be fetched from the main data-storage\n",
    "  * Local jupyter execution, when the model is selected from the drop-down\n",
    "  \n",
    "2. Experiment execution: Calling train/eval/test and waiting for the results. SenseTheFlow is asynchronous by default, which means that all executions are done in a background thread. Some mechanisms are provided to block until certain events\n",
    "  * `wait_ready` might be used to wait until the experiment actually starts running (waits until tensorflow has setup the GPU memory and starts iterating)\n",
    "  * `wait_for` can be used to wait for a certain number of steps or seconds\n",
    "  * `wait` can be used to block until the experiment completely finishes\n",
    "  \n",
    "Alternatively, asynchronous execution can be turned off by specifying `sync=True` to any of the calls above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def once_discovered(experiment):\n",
    "    # Call train, by default will:\n",
    "    #  * checkpoint_steps=1000, saves the model every 1000 steps\n",
    "    #  * summary_steps=100, saves summaries every 100 steps\n",
    "    #  * config=None, which means it will *not* use all gpus, but gradually expand memory\n",
    "    # By default the model is executed in a background thread, which might be a BAD idea\n",
    "    #  if you have errors and want to find them\n",
    "    #  use sync=True to block and run normally\n",
    "    print('TRAIN')\n",
    "    context = experiment.train(dataset_fn)\n",
    "    \n",
    "    # Wait until it actually is running\n",
    "    context.wait_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As always, you may not want debug messages\n",
    "\n",
    "import logging\n",
    "logger = tf.get_logger()\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dc17251dd1e469498145186a97c261e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2536ee7db245478797907bbc3631a75e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0079c61c2bc54054a09f03ad4ae899c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# By default everything is run in Graph mode (ie. compiled, fast). It can be optionally executed eagerly (step by step) by using\n",
    "#tf.config.experimental_run_functions_eagerly(True)\n",
    "\n",
    "# Supply the name, model CLASS, params and where to write\n",
    "experiment = Experiment(params['model_name'], MNIST, params=params, persistent_path=os.path.join('/tmp/', params['model_name']))\n",
    "# Tell it which GPU to use\n",
    "experiment.assign_gpu(1)\n",
    "# And search for existing models\n",
    "experiment.run_local(once_discovered, prepend_timestamp=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Waiting\n",
    "\n",
    "An experiment can be waited, in general, by calling any of `wait_ready` or `wait`. As opposed to waiting on a context, waiting on an experiment will wait for all individual runs to end (for example, wait for both train and eval to end)\n",
    "\n",
    "It is encoraged to call `wait_ready` before continuing, to ensure the context is registered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.wait_ready()\n",
    "# experiment.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further using the context\n",
    "\n",
    "The training `context` above, inside `once_discovered`, can be recovered with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As it is the first and only call to train, out context is in position [0] of Mode.TRAIN\n",
    "# Further calls would be in next positions, ordered by call order always\n",
    "\n",
    "context = experiment.get_context(Mode.TRAIN)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can do either of this:\n",
    "\n",
    "# context.save()\n",
    "# context.reattach() # Redraws the TQDM bars\n",
    "# context.stop() # Stops training\n",
    "\n",
    "# Wait until it finishes, can exit waiting by pressing stop or CTRL+C, training won't be affected.\n",
    "# context.wait()\n",
    "\n",
    "context.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
