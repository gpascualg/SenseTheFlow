{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Sample\n",
    "\n",
    "This notebook creates a sample model for MNIST using Tensorflow and SenseTheFlow.\n",
    "\n",
    "As a sample, it is an overkill that will use Keras Resnet50 implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from SenseTheFlow.experiment import Experiment, Mode, ExperimentOutput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Model\n",
    "\n",
    "Models are now sub-classes from `tf.keras.Model`. This is to make user code and the library itself compatible with future Tensorflow 2.0 usage.\n",
    "\n",
    "Such models should:\n",
    "* Define layers in its `__init__(self, mode, params)` constructor. The easiest way to do so would be by using either `tf.keras.layers` or `keras.layers`.\n",
    "* Call layers in its `call(self, x, y, mode, params)` method.\n",
    "\n",
    "The `call` method must return a `ExperimentOutput` instance. Its property `loss` must be different from `None`, either a tensor or a constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST(tf.keras.Model):\n",
    "    def __init__(self, mode, params):\n",
    "        # Always call `super` constructor\n",
    "        super(MNIST, self).__init__()\n",
    "        \n",
    "        # Define layers\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=16, kernel_size=3, activation='relu', padding='same', data_format='channels_first')\n",
    "        self.conv2 = tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', padding='same', data_format='channels_first')\n",
    "        self.conv3 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same', data_format='channels_first')\n",
    "        self.pool = tf.keras.layers.GlobalAveragePooling2D(data_format='channels_first')\n",
    "        self.dense = tf.keras.layers.Dense(10)\n",
    "        \n",
    "    def call(self, x, y, mode, params):\n",
    "        # Call layers\n",
    "        outputs = self.conv1(x)\n",
    "        outputs = self.conv2(outputs)\n",
    "        outputs = self.conv3(outputs)\n",
    "        outputs = self.pool(outputs)\n",
    "        logits = self.dense(outputs)\n",
    "        \n",
    "        # When `mode == Mode.TEST`, `y` will be None\n",
    "        loss = 0.0\n",
    "        train_op = None\n",
    "        if mode != Mode.TEST:\n",
    "            # Compute loss\n",
    "            loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "            loss = tf.reduce_mean(loss)\n",
    "        \n",
    "            # Compute gradients and apply them\n",
    "            global_step = tf.train.get_or_create_global_step()\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate=params['learning_rate'])\n",
    "            train_op = optimizer.minimize(loss, global_step)\n",
    "        \n",
    "        # `call` must return `ExperimentOutput`, and it must be constructed as a \"key=value\" object\n",
    "        return ExperimentOutput(\n",
    "            outputs={\n",
    "                'probabilities': tf.nn.softmax(logits),\n",
    "                'number': tf.argmax(logits)\n",
    "            },\n",
    "            train_op=train_op,\n",
    "            loss=loss\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the data pipeline\n",
    "\n",
    "It can be done in multiple ways, the only restriction is for your `dataset_fn` to return a `tf.Dataset` instance. Here, we will use `Keras` to directly obtain images and labels, but one could read from disk or whatever other option.\n",
    "\n",
    "Here using a generator might not be the best idea (performance-wise), as we have all data already loaded into RAM. However, the general case will be generators, thus it is the pipeline used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_generator():\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "    for image, label in zip(x_train, y_train):\n",
    "        # Here we simply yield two values, but you could easily construct other returns.\n",
    "        # More examples are provided below\n",
    "        yield image[..., np.newaxis], label\n",
    "        \n",
    "# `dataset_fn` always receives the run `mode`.\n",
    "def dataset_fn(mode, params):\n",
    "    # Create a dataset from a geneator\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        generator=mnist_generator, \n",
    "        output_types=(tf.float32, tf.int32),\n",
    "        output_shapes=([28, 28, 1], None)\n",
    "    )\n",
    "\n",
    "    # Batch inputs, make sure all batches are equal-sized (drop_remainder=True)\n",
    "    dataset = dataset.batch(params['batch_size'], drop_remainder=True)\n",
    "    # Prefetch some batches\n",
    "    dataset = dataset.prefetch(8)\n",
    "    # Repeat for 100 epochs, leave blank to repeat indefinately\n",
    "    dataset = dataset.repeat(100)\n",
    "    # Return the dataset\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the experiment\n",
    "\n",
    "Experiments are executed in two steps:\n",
    "\n",
    "1. Experiment discovery: That is, given the experiment name (or model name) find the corresponding saved checkpoint (if any). This process might not be completed immediately due to:\n",
    "  * Remote execution, when the model has to be fetched from the main data-storage\n",
    "  * Local jupyter execution, when the model is selected from the drop-down\n",
    "  \n",
    "2. Experiment execution: Calling train/eval/test and waiting for the results. SenseTheFlow is asynchronous by default, which means that all executions are done in a background thread. Some mechanisms are provided to block until certain events\n",
    "  * `wait_ready` might be used to wait until the experiment actually starts running (waits until tensorflow has setup the GPU memory and starts iterating)\n",
    "  * `wait_for` can be used to wait for a certain number of steps or seconds\n",
    "  * `wait` can be used to block until the experiment completely finishes\n",
    "  \n",
    "Alternatively, asynchronous execution can be turned off by specifying `sync=True` to any of the calls above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def once_discovered(experiment):\n",
    "    # Call train, by default will:\n",
    "    #  * checkpoint_steps=1000, saves the model every 1000 steps\n",
    "    #  * summary_steps=100, saves summaries every 100 steps\n",
    "    #  * config=None, which means it will *not* use all gpus, but gradually expand memory\n",
    "    print('TRAIN')\n",
    "    context = experiment.train(dataset_fn)\n",
    "    \n",
    "    # Wait until it actually is running\n",
    "    context.wait_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'model_name': 'mnist-test',\n",
    "    'learning_rate': 3e-4,\n",
    "    'batch_size': 128,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "822e58f3bd654cf4aac96b6b51982171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3477eee5cd3f468bb109977298610254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "475cac42c932484687fec56519c4cb3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment = Experiment(params['model_name'], MNIST, params=params, persistent_path=os.path.join('/tmp/', params['model_name']))\n",
    "experiment.assign_gpu(1)\n",
    "experiment.run_local(once_discovered, prepend_timestamp=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Waiting\n",
    "\n",
    "An experiment can be waited, in general, by calling any of `wait_ready` or `wait`. As opposed to waiting on a context, waiting on an experiment will wait for all individual runs to end (for example, wait for both train and eval to end)\n",
    "\n",
    "It is encoraged to call `wait_ready` before continuing, to ensure the context is registered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.wait_ready()\n",
    "# experiment.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further using the context\n",
    "\n",
    "The training `context` above, inside `once_discovered`, can be recovered with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As it is the first and only call to train, out context is in position [0] of Mode.TRAIN\n",
    "# Further calls would be in next positions, ordered by call order always\n",
    "\n",
    "context = experiment.get_context(Mode.TRAIN)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can do either of this:\n",
    "\n",
    "# context.save()\n",
    "# context.reattach() # Redraws the TQDM bars\n",
    "# context.stop() # Stops training\n",
    "\n",
    "# Wait until it finishes, can exit waiting by pressing stop or CTRL+C, training won't be affected.\n",
    "# context.wait()\n",
    "\n",
    "context.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
